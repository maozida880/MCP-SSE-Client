# 12306-MCP 客户端环境变量配置

# ==========================================
# LLM API 配置（必需）
# ==========================================

# DeepSeek API Key（必需）
DEEPSEEK_API_KEY="your_deepseek_api_key_here"

# ==========================================
# 可选配置（config.json 优先）
# ==========================================

# 如果不使用 config.json，可以通过以下环境变量配置

# MCP 服务器地址（默认：http://localhost:12306）
# MCP_SERVER_URL="http://localhost:12306"

# LLM Base URL（默认：https://api.deepseek.com）
# BASE_URL="https://api.deepseek.com"

# LLM 模型名称（默认：deepseek-chat）
# MODEL="deepseek-chat"

# 配置文件路径（默认：config.json）
# CONFIG_PATH="config.json"

# ==========================================
# 其他 LLM 提供商示例
# ==========================================

# OpenAI
# DEEPSEEK_API_KEY="sk-your_openai_api_key"
# BASE_URL="https://api.openai.com/v1"
# MODEL="gpt-4-turbo"

# Ollama（本地模型）
# DEEPSEEK_API_KEY="ollama"
# BASE_URL="http://localhost:11434/v1"
# MODEL="qwen2:7b"

# ==========================================
# 使用说明
# ==========================================
# 1. 复制此文件为 .env
# 2. 填写你的 DEEPSEEK_API_KEY
# 3. 其他配置建议使用 config.json 管理
